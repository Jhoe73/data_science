{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7479,"status":"ok","timestamp":1721960179851,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"WZmRPDeEwtGU","outputId":"1b31afad-9d8b-4f02-fca1-12084df7d9bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.37.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.1\n"]}],"source":["!pip install openai\n","!pip install python-dotenv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Yixe4Zl0zmC"},"outputs":[],"source":["# Crie um arquivo .env e adicione a chave de API\n","with open(\".env\", \"w\") as f:\n","    f.write(\"API_KEY\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2966,"status":"ok","timestamp":1721963469584,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"yFA-4aOEvw5Z","outputId":"4d597b00-5f6f-4d88-cb2a-f0768f5d734b"},"outputs":[{"name":"stdout","output_type":"stream","text":["This is a test."]}],"source":["from dotenv import load_dotenv\n","import os\n","from openai import OpenAI\n","\n","# Carregue as variáveis de ambiente do arquivo .env\n","load_dotenv()\n","\n","client = OpenAI(\n","    # This is the default and can be omitted\n","    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",")\n","\n","client = OpenAI()\n","\n","# Passo 3: Faça uma chamada à API usando a nova interface\n","stream = client.chat.completions.create(\n","    model=\"gpt-4\",\n","    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n","    stream=True,\n",")\n","for chunk in stream:\n","    print(chunk.choices[0].delta.content or \"\", end=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3603,"status":"ok","timestamp":1721961908678,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"v3ItlgXp5aYJ","outputId":"44378f29-024e-440c-cfee-f989d5d78547"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n","Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n"]}],"source":["pip install pydub ffmpeg-python moviepy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ij1RoQG8_0K"},"outputs":[],"source":["!apt-get install -y ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3224,"status":"ok","timestamp":1721962159612,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"1Cn3dvXh8UPT","outputId":"044eb486-0e36-4e4e-d4e4-3aaaa2dba24b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n"]}],"source":["pip install --upgrade moviepy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3650,"status":"ok","timestamp":1721962181404,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"K49oBor98Zwf","outputId":"fd9e59a4-7258-4ce1-b510-122092a8bd3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"]}],"source":["pip install pydub\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":732},"collapsed":true,"executionInfo":{"elapsed":448,"status":"error","timestamp":1721967542789,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"24IBFJgs5eeu","outputId":"68a03475-ebac-4250-e372-fcc3778598db"},"outputs":[{"ename":"CouldntDecodeError","evalue":"Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58c754f8f040] moov atom not found\n/content/Modelos.mp4: Invalid data found when processing input\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCouldntDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-3f4464ff26fe>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Carregar o áudio do vídeo MP4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Exportar o áudio como MP3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             raise CouldntDecodeError(\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \"Decoding failed. ffmpeg returned error code: {0}\\n\\nOutput from ffmpeg/avlib:\\n\\n{1}\".format(\n\u001b[1;32m    775\u001b[0m                     p.returncode, p_err.decode(errors='ignore') ))\n","\u001b[0;31mCouldntDecodeError\u001b[0m: Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58c754f8f040] moov atom not found\n/content/Modelos.mp4: Invalid data found when processing input\n"]}],"source":["from pydub import AudioSegment\n","import os\n","\n","# Caminho para o arquivo MP4\n","input_video = \"/content/modelos.mp4\"\n","\n","# Caminho para o arquivo de saída MP3\n","output_audio = \"/content/modelos.mp3\"\n","\n","# Carregar o áudio do vídeo MP4\n","audio = AudioSegment.from_file(input_video, \"mp4\")\n","\n","# Exportar o áudio como MP3\n","audio.export(output_audio, format=\"mp3\")\n","\n","print(\"Conversão concluída com sucesso!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32802,"status":"ok","timestamp":1721967835142,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"QGfUINeM9MBX","outputId":"97d8004b-559b-4903-e797-ff05990a3884"},"outputs":[{"name":"stdout","output_type":"stream","text":["Divisão concluída com sucesso!\n","Partes geradas: ['/content/div3/part_1.mp3']\n"]}],"source":["def split_audio(file_path, output_folder, max_size=25 * 1024 * 1024):\n","    audio = AudioSegment.from_file(file_path)\n","    # Taxa de bits média em bits por segundo (bps)\n","    bitrate = 128 * 1024  # 128 kbps\n","    max_duration_ms = (max_size * 8 * 1000) / bitrate  # Converter para milissegundos\n","\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    parts = []\n","    part_index = 1\n","    start_ms = 0\n","\n","    while start_ms < len(audio):\n","        end_ms = start_ms + max_duration_ms\n","        if end_ms > len(audio):\n","            end_ms = len(audio)\n","\n","        part = audio[start_ms:end_ms]\n","        part_path = os.path.join(output_folder, f\"part_{part_index}.mp3\")\n","        part.export(part_path, format=\"mp3\")\n","\n","        parts.append(part_path)\n","        part_index += 1\n","        start_ms = end_ms\n","\n","    return parts\n","\n","# Caminho para o arquivo MP3\n","input_audio = \"/content/Modelos.mp3\"\n","\n","# Pasta para salvar os arquivos divididos\n","output_folder = \"/content/div3\"\n","\n","# Dividir o áudio\n","parts = split_audio(input_audio, output_folder)\n","\n","print(\"Divisão concluída com sucesso!\")\n","print(\"Partes geradas:\", parts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63801,"status":"ok","timestamp":1721967946762,"user":{"displayName":"Jhoe","userId":"00628288210876534392"},"user_tz":180},"id":"aNfoLNs9-vR1","outputId":"f4250bca-c1fe-4227-98a4-62a4f6d49e93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Transcrevendo parte 1 de 1\n","Transcrição final:\n","Nós convidamos o Roberto Figueira, Roberto, você já conhece, e só para eu contar qual é o título, qual é o tema, o Roberto Figueira, ele é Superintendente de Engenharia da Plataforma de Dados e Ferramentas Analíticas do Itaú Unibanco. Ele é bacharel, mestre e doutor em Ciências de Computação. Possui mais de 15 anos de experiência no mercado financeiro, também se ele souber como é o nome disso. Passando por projetos nas áreas de dados, de metadata, de plataforma de risco de crédito, de data house, de BI, de HPC e modernização e mainstream. Nos últimos dois anos se testificou a mitigar o data lake para a nuvem e estruturação e implementação do modelo arquitetural diretamente na corporação. O Roberto vai falar hoje, gente, do modelo de IA, que é só a ponta do iceberg. O que está nos bastidores e algumas dicas que eu acho que é o mais importante para organizar os seus dados com sucesso. Então, Roberto, você. Obrigada, gente. Obrigado, Silvana. Esqueci de falar que eu sou filho da casa. Tudo isso que ela falou aqui, mestre, bacharel, prologue, foi lá no ICMC, foi um das duas. Eu aprendi prologue. Vocês já viram isso no IPN, não, mãe? Aprendi prologue com ela. Foi um dos primórdios da tendência especial simbólica. Eu acho que é uma simbólica. Foi interessante. E, enfim, fiz o doutorado depois lá também do ICMC, na área de dados com Caetano e Águia. E vocês foram alunos do Caetano e Águia também. Esse rapaz aqui foi contemporâneo meu de doutorado. E ganhou o prazer de participar desse evento. Eu sei que o nome é bem clichê, não é? Ponto da iceberg, mas tinha uma razão para isso. Depois eu até pensei em mandar o título. O que me acontece? A gente olha ali a parte de modelagem, quando vai fazer o trailer, né? A construção dos modelos. Ele acaba sendo até um pouco rápido, mas o que vem por trás disso, para você que gosta de treinar o modelo, vai levando muito a complexidade. E é um pouco do que eu vou falar aqui, de como a gente pode melhorar, reduzir essa complexidade. Aqui é institucional. Então, só um slide institucional, falando um pouco do que é a UDAURU. É uma empresa que a gente paga 68 bilhões de dólares. É a marca mais valiosa da América do Sul, com 8 bilhões de dólares. Temos quase 100 mil colaboradores só no Brasil. E aí tem o resto em Norte. É um bom lugar para trabalhar. Eu sou 15 anos da empresa. Controlo isso. E temos várias pacientistas de dados, engenheiros de dados. Tudo se fala em todos os dados. Nós temos, inclusive, governantes, que temos espaço para isso. Então, um pouco de o que é a UDAURU, completando 100 anos esse ano. O que é uma etapa de modelagem? Só para a gente trazer aqui uma visão, na mesma parte. Apesar disso ser uma visão bem de mercado, não é... Eu tenho curiosidade em cheque de PT, então é praticamente a mesma coisa. Primeira coisa que acontece. E tem esse merda de negócio. Eu vou depois entrar em cada um deles, explicar as complexidades. Entendimento de negócio. A área que precisa de um modelo de machine learning, tem um cientista que fala assim, olha, eu preciso aumentar a profissão na compra de um determinado produto. Eu preciso reduzir o volume de fraudes. Eu preciso melhorar a experiência do cliente. Eu preciso entender como é bom fazer isso. Existe um problema de negócio que é onde nasce o modelo. Esse problema de negócio é conversado com o cientista. E eu estou com uma discernação disso, um entendimento aprofundamento de algum problema, e aí começa então todo o resto. Identificar e obter o dado. Bom, o dado vira problema. Quais são os dados que podem ajudar a resolver aquele problema? Como é que eu vou avaliar se há fraude ou não há fraude? Como é que eu vou avaliar a profissão de um cliente de uma equidade de imprensa? Quais são os dados que podem responder a isso? Uma vez que a gente entendeu, a gente ficou com o dado, vem o entendimento e a preparação dos dados. O dado de uma maneira como ele é gerado é o dado de uma comparação. Precisa ser trabalhado. A partir daí você treinar o modelo e também ter aí um trabalho orgânico. Aí vem a construtiva e validação do modelo. Qual é isso? A pontinha dele, né? O resto está tudo embaixo do cérebro. Isso aqui é rápido. Praticamente rápido. Uma vez que você tem os dados, você tem as variáveis construídas, você treinar o modelo, ele vai se automatizar. E por fim, vem a implantação do modelo. Que é talvez a parte mais custosa e mais complexa. Aqui tem um exemplo de uma visão de como isso, qual é a dinâmica disso ao longo dos dias. É também uma coisa de indústria e é muito preciso. Entendimento do negócio. E aí você tem vários ciclos de vida de uma vez que você entende o negócio, você tem os dados que respondem, volta de novo para o entendimento, aposentamento e volta para entender o dado. Uma vez que você definiu quais são os dados, você prepara o dado, tem profissionais de modelagem que você pode trabalhar de novo com algumas variáveis adicionais. Avaliação e validação do modelo para ver se a performance atende, performance estatística no caso, não é performance de processamento. Uma vez que todo esse ciclo aqui atinge os objetivos do negócio, a gente vai para a fase de redeployment, vai para a introdução, e aí a gente vai explicar um pouco sobre isso. Só para vocês terem uma ideia de por que eu falo que isso é um computador experimental, se você estiver com o trabalho maduro, tudo isso pode ser feito em 3 meses. Se você não tiver boas práticas, isso pode levar em menos de um ano e pode acontecer até de passar um ano e meio. Eu já vi um ano e meio para colocar um modelo no ar. Aí você fala assim, mas você levou um ano e meio para colocar um modelo no ar? Será que o problema de negócio ainda é o mesmo? Será que ele responde a necessidade de negócio? Então, um pouco do que eu vou falar aqui é exatamente de por que isso acontece e como a gente pode acelerar e evitar todo esse prazo. Vamos lá. O que é identificar o dado? Qual é a problemática aqui? Só para vocês terem uma ideia, eu sei que... Aliás, é uma pergunta que eu queria fazer. A maior parte... Quem daqui é de tecnologia? Vou fazer a pergunta ao contrário. Quem não é de tecnologia? Deita a lente no meio para vocês. Se eu falo que não tem um técnico aqui, por favor, levanta a mão e eu explico. Mas então, deita a lente onde você fala que colocava boa parte dos dados da população. O novo histórico cultural egípcio, vamos falar aqui, seria uma palestra só de modelos arquiteturais para o armazenamento de dados. Mas, imagina, no Itaú, nós temos hoje o Data Lake e eu vou fazer uma outra separação conceitual aqui. Nós temos dados produtivos. Dados produtivos são aqueles que são gerados ou partidos do sistema produto. Outra corrente é o sistema produto. Sistema de financiamento é o sistema produto. FIX é o sistema produto. É o sistema produto. O dado que é gerado ou partido é armazenado, já chamamos de camada produtiva. Geralmente é um processo ordem. É um processo construído sistematicamente por o pessoal de TI. E nós temos a camada de usuário, onde o usuário trabalha mudando, faz análise, vende o dado, compara o modelo. Nessa camada produtiva, de tabelas que podem ser consultadas e usadas para construção de modelos, dá 115 mil. Aí você fala assim, chega um problema de negócio. Como que você vai encontrar qual é a tabela que vai responder ao problema de negócio? Isso é um problema. E gasta-se muito tempo para identificar quais são as aplicações e as tabelas que vão responder. Em uma fase de baixa maturidade, conta-se muito com o conhecimento humano dentro da empresa. E aí você começa a colocar mais tempo. Daí que começa a aparecer nove meses da linha. Identificar quais são as tabelas, pedir nove meses, é identificação e manutenção. Esse é um dos pontos que traz bastante uso no processo de desenvolvimento do modelo. Uma vez que você encontra, os conceitos que estão nas tabelas não estão uniformizados com as linhas de negócio. São parênteses aqui. Itaú é um encanto multi-plano. Ele sai desde conta-corrente até corretora, investimento, vários produtos. Quando você vai em conta-corrente, a data de contratação, o nome do atributo, conceito, data de contratação é a data quando você assina e abre. Assina o contrato e abre. Quando você vai para o cartão de crédito, a data de contratação é a data que você traz a primeira ativização do cartão de crédito. O conceito, às vezes, não é uniforme, mas é uniforme porque um negócio tem o conceito uniforme. Mas quando é na lista de dados, se ele não souber disso, ele vai tratar a data de contratação como uma mesma coisa. Eu estou dando só um exemplo. Cada linha de negócio pode ter conceitos diferentes para diferentes atributos. Isso traz complexidade para entender o trato. Entender o nome técnico do atributo. Vou dar um exemplo bobinho assim. Código Plat com AMP1. Códigos, plataformas, comerciais, empresas. E o que é o I? Quais são as empresas que estão lá dentro e quais não estão? Entender o nome técnico de um atributo, de uma tabela, às vezes, também não é trivial. Por que a gente faz o acrônimo da tabela? Porque há diferentes tecnologias que o tamanho do nome da tabela com outro tipo de tabela, mas eu vou fazer um exemplo de coluna. O nome de um atributo, às vezes, no campo de dados, ele não consegue colocar o nome em distância. Então, aí, se não tiver um limite, as pessoas são criativas. Elas ficam erigidas no nome do atributo. Isso traz dificuldade de entendimento do dado e de identificação do dado. Outra coisa, existe também, às vezes, uma atividade de baixa qualidade do metadado. O metadado são os dados que definem o dado. No curso, vocês falam de metadado. Se eu precisar entrar no detalhe e explicar de novo, eu explico para a pessoa. Mas, existe uma baixa qualidade no nome técnico do atributo. Eu já vi que as pessoas colocaram a tabela e ele queria passar isso para a posição. A tabela estava lá e ele falava assim, nome, endereço, coluna 1.2, coluna 2, coluna 4. Para ele, que é engenheiro de software, ele entregou o projeto dele, fez a aplicação transacional. Para quem está na camada analítica, isso não tem significado nenhum. E aí começa, inclusive, um problema sério para quem é um modelador. E, às vezes, a ausência de glossário nos negócios. Como explicar aqueles acrônitos com os conceitos? O glossário ajuda bastante nisso daí. Esses são os desafios que a empresa tem. Como é que você pode trabalhar cada um deles? Então, tem uma lista de recursos, onde o endereço está aberto. Um banco de dados com uma facilidade de busca, um Google, você joga lá, eu quero encontrar dados hoje em consignado. Então, ele vai lá e lista todos os dados em relação ao consignado. Esse é um exemplo. Estabelecer um funcionário de dados corporativo. E aqui é um desafio para quem escolhe governança. Toda pessoa que trabalha com governança quer ser desejada pelo pessoal de produção, de modificação. Porque o governante tem a função de não deixar passar coisas que não funcionam. E o engenheiro tem a missão de entregar o mais rápido possível. Então, ele joga os valores e os incentivos aqui dentro. Mas esses heróis de governança é que mantém o trabalho dos cientistas de dados menos oneroso. Então, se vocês estão na área de negócio, incentivem os seus engenheiros, quando vocês fizerem a demanda, incentivem os seus engenheiros a dar a mão de bolsa com as formulas e a documentar bem o que vocês conseguirem. Defini processos de política de cadastramento de metadados. Toda hora que você for cadastrar de dentro, aí entra um pouco de... Num primeiro momento, você pode ter um processo mais manual de revisão de processo. Inclusive, dizer que não pode e fica lá... Uma das coisas que nós estamos fazendo agora bastante para diminuir o atrito entre o engenheiro e a governança é usar redes sociais e colaboração para ajudar na aprimoração da documentação e do nome da coluna. O que eu quero dizer com isso? Uma vez que tem ali a descrição da tabela e a descrição dos atributos, a definição conceitual de negócios dos atributos, quem consome pode eventualmente dizer, olha, não gostei da definição disso aqui. Você deveria aplicar essa definição dentro do poder colaborativo. O poder de colaboração desse aprimoramento é exponencial. Toda organização basta ajudar na construção e na revisão do poder. Isso diminui o atrito com o governante. E acelera a coletividade. Você basta ter várias pessoas ajudando a construir o poder colaborativo nos seus demandados. Uma maneira de você verificar se aquele metadata é bom ou não. Outra coisa que nós fizemos também. Na hora que o seu engenheiro coloca lá pode, tem, pode, tem, a gente está usando agora esse metadata AI para ajudar a esquecer automaticamente os metadatas. Ele pega o nome da coluna, o nome dele, e traz a definição de negócio para aquele conceito. E já com ferramentas de mercado você também. Novamente, falando de avia da cadastração de metadatos, mas aqui também falo de processos de governança, de maneira mais ampla. Tudo isso aqui que eu estou colocando, é facilmente feito com uma ferramenta de gestão de metadatos. E aí tem vários no mercado que atuam com muitas dessas funcionalidades aqui e ajudam bastante na partilha de distribuição de dados. A gente vê aquela parte ali de de licitar e buscar a coluna. Obter o dado. Uma vez que você verificou quais são os dados que você quer, você tem duas situações. O dado está no leite, está perto dos 15 dias, o dado não está no leite. Você vai ter que abrir um demander e solicitar que lá no sistema produto, sistema origem, ele faça a extração do dado e todo o processo, porém processo produtivo, vai carregar o dado dentro do leite. Isso pode levar dois, três meses, independente de como você está lá. E contribui para que esse dado comece a funcionar. Então a inicidência do dado em ambiente jornalístico. Outra coisa que usam as listas que os serviços de dados recomendam. As listas da empresa grande, devido a fusão e a precisão, o serviço vai ter vários ambientes de dados. O ambiente de dados mais comum em um banco, todo o banco tem, é a pesquisa em balaçadas. Não sei se vocês conhecem, se já trabalharam com isso, mas ela foi a grande estatística lá dos anos 2000 e isso espalhou no banco, em todos os bancos produtores, aqui fora do Brasil. Ao longo do tempo vieram as outras tecnologias, detector house, depois data lake, e agora moleque house, em todas as arquiteturas. Isso acaba deixando dentro da concordação alguns ambientes, vamos modernizar e vamos para aquele. Então a gente vai para lá e depois ativa isso. Errado, vamos deixar. E aí começa a ter noite, quarenta, quatro minutos, ou que o nosso referente que viu a empresa e ela tinha o detector house lá dentro e o detector house aos segundos. Qual é a consequência de múltiplos ambientes de dados? Exatamente, às vezes os dados não estão harmonizados e estruturados do mesmo tipo de dados, do mesmo conceito assim por diante. Gasta-se também tempo de conectar esses ambientes, tirar a voz dos dados, anonizar e aí montar o dado para alimentar o modelo. Tentar a qualidade dos dados na camada analítica. Às vezes os dados saem do sistema organizacional e entram no lake, mas não há uma visão clara da qualidade deles. O processo de extensão. Todo mundo comete erro na hora de pegar o mar. Mas a extração, por alguma razão, implementou uma coisa nova e disposicionou o arquivo, gerou um plano inteiro em pleno. E o processo no modelo está rodando diariamente. Passam dois, três dias e o modelo começa a ter um comportamento completamente equivocado e quando vão analisar e descobrir, já passou uma semana e o dado que está dentro do sistema organizacional tem uma cor linterna e branca. Não ter um processo de tratamento de qualidade é incrivelmente prejudicial. Normalmente quando você traz o dado do sistema no local, você passa um processo de qualidade para evitar que isso se propague para frente. Outra coisa que parece simples, mas não é. Omitir a autorização para a exceção de dados. Principalmente conforme esse dado é mais terno de dado que aliás hoje é um dado mais sensível, maiores se trazem para você ter acesso a ele. Isso também causa uma consequência não tão grande, mas ajuda naquele stop-loss ali. É... Eu não lembro de você trabalhar com a questão do dado existente. É você trazer uma cultura de analítica para design e trazer a visão de, se você está construindo um produto digital, você tem que pensar nesse produto digital já na camada analítica. Não é só no transacional. Não é só o processo que você vai fixar. Como é que ele faz o débito ou o crédito numa conta corrente. Como é que eu posso fazer esse fix, já entrar no dado elétrico para poder fornecer alguma capacidade analítica para prevenção a fraude? Como é que esse fix eu posso colher mais informações para poder ajudar a experiência do usuário? Que informações adicionais eu tenho para lá? E imediatamente criar dentro do sistema transacional um processo que replica o dado, que é o system record. O record é o que você registra, o registro da transação. Fazer uma réplica desse registro dentro de um ambiente meio, proativamente. Isso reduz muito o atrito da inexistência do dado. Outra coisa, tem uma arquitetura de referência que traga como conceito a unicidade de um ambiente. Ter um único ambiente de dados. E cada vez que você faz a aquisição de uma empresa, a gente transporta isso por essa arquitetura, de alguma maneira. Trabalhando isso com concílio, para sempre ter até um único ambiente de dados e acabada dentro da lei. Você pode, a partir dele, ter ambientes elétricos puxando o dado desse ambiente.\n"]}],"source":["def transcribe_audio_part(audio_path):\n","    with open(audio_path, \"rb\") as audio_file:\n","        transcription = client.audio.transcriptions.create(\n","          model=\"whisper-1\",\n","          file=audio_file\n","        )\n","        return transcription.text\n","\n","def transcribe_and_concatenate(audio_folder, max_parts=10):\n","    transcriptions = []\n","    audio_files = sorted([os.path.join(audio_folder, f) for f in os.listdir(audio_folder) if f.endswith('.mp3')])\n","    for i, part in enumerate(audio_files):\n","        if i >= max_parts:\n","            break\n","        print(f\"Transcrevendo parte {i + 1} de {min(len(audio_files), max_parts)}\")\n","        text = transcribe_audio_part(part)\n","        transcriptions.append(text)\n","    return \" \".join(transcriptions)\n","\n","# Função para salvar a transcrição em um arquivo .txt\n","def save_transcription_to_file(transcription, file_path):\n","    with open(file_path, \"w\") as file:\n","        file.write(transcription)\n","\n","# Pasta contendo as partes de áudio divididas\n","audio_folder = \"/content/div3\"\n","\n","# Limitar a 10 partes para teste\n","final_transcription = transcribe_and_concatenate(audio_folder, max_parts=5)\n","\n","# Caminho do arquivo .txt para salvar a transcrição\n","output_file_path = \"/content/modelos.txt\"\n","\n","# Salvar a transcrição no arquivo .txt\n","save_transcription_to_file(final_transcription, output_file_path)\n","\n","print(\"Transcrição final:\")\n","print(final_transcription)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMbtySjuOHWibbonurcUlsk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
